{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic — Step‑by‑Step Master Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Lesson 1: Lesson 2: Pydantic Basics\n",
    "\n",
    "> This section comes from the uploaded notebook. Execute the cells in sequence. Where needed, earlier imports/utilities are repeated for clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini‑Index\n",
    "\n",
    "- Lesson 2: Pydantic Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16503865",
   "metadata": {},
   "source": [
    "# Lesson 2: Pydantic Basics\n",
    "\n",
    "In this lesson, you'll learn the fundamentals of Pydantic models for data validation using a customer support system as your example application. You'll see how to define data models, validate user input, and handle validation errors gracefully.\n",
    "\n",
    "By the end of this lesson, you'll be able to:\n",
    "- Create Pydantic models to validate user input data\n",
    "- Handle validation errors with proper error handling\n",
    "- Use optional fields and field constraints in your models\n",
    "- Work with JSON data validation methods\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313faba4",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for the lesson\n",
    "from pydantic import BaseModel, ValidationError, EmailStr\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abffb4e5",
   "metadata": {},
   "source": [
    "### Define a UserInput Pydantic model and populate it with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb4703",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Create a Pydantic model for validating user input\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ecbe4",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Create a model instance\n",
    "user_input = UserInput(\n",
    "    name=\"Joe User\", \n",
    "    email=\"joe.user@example.com\", \n",
    "    query=\"I forgot my password.\"\n",
    ")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e9422",
   "metadata": {},
   "source": [
    "### Note: the following cell will produce a validation error. You can correct the error by following along with the video, or just proceed with the rest of the notebook as cells below do not depend on this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c9900",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Attempt to create another model instance with an invalid email\n",
    "user_input = UserInput(\n",
    "    name=\"Joe User\", \n",
    "    email=\"not-an-email\", \n",
    "    query=\"I forgot my password.\"\n",
    ")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bcdd0",
   "metadata": {},
   "source": [
    "### Define a function for error handling and try different inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482a1a0",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# Define a function to handle user input validation safely\n",
    "def validate_user_input(input_data):\n",
    "    try:\n",
    "        # Attempt to create a UserInput model instance from user input data\n",
    "        user_input = UserInput(**input_data)\n",
    "        print(f\"✅ Valid user input created:\")\n",
    "        print(f\"{user_input.model_dump_json(indent=2)}\")\n",
    "        return user_input\n",
    "    except ValidationError as e:\n",
    "        # Capture and display validation errors in a readable format\n",
    "        print(f\"❌ Validation error occurred:\")\n",
    "        for error in e.errors():\n",
    "            print(f\"  - {error['loc'][0]}: {error['msg']}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e0606",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Create an instance of UserInput using validate_user_input() function\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\", \n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I forgot my password.\"\n",
    "}\n",
    "\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847c1c2",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Attempt to create an instance of UserInput with missing query field\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\", \n",
    "    \"email\": \"joe.user@example.com\"\n",
    "}\n",
    "\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0e095",
   "metadata": {},
   "source": [
    "### Update your UserInput data model with additional fields and experiment with different input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a33ab",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Import additional libraries for enhanced validation\n",
    "from pydantic import Field\n",
    "from typing import Optional\n",
    "from datetime import date\n",
    "\n",
    "# Define a new UserInput model with optional fields\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d39791",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "# Define a dictionary with required fields only\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I forgot my password.\"\n",
    "}\n",
    "\n",
    "# Validate the user input data\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39c3ae",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54589363",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Define a dictionary with all fields including optional ones\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": f\"\"\"I bought a laptop carrying case and it turned out to be \n",
    "             the wrong size. I need to return it.\"\"\",\n",
    "    \"order_id\": 12345,\n",
    "    \"purchase_date\": date(2025, 12, 31)\n",
    "}\n",
    "\n",
    "# Validate the user input data\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa20287b",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# Define a dictionary with all fields and including additional ones\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": f\"\"\"I bought a laptop carrying case and it turned out to be \n",
    "             the wrong size. I need to return it.\"\"\",\n",
    "    \"order_id\": 12345,\n",
    "    \"purchase_date\": date(2025, 12, 31),\n",
    "    \"system_message\": \"logging status regarding order processing...\",\n",
    "    \"iteration\": 1 \n",
    "}\n",
    "\n",
    "# Validate the user input data\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472fa30",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62d5b6",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "# Create an instance of UserInput with valid data\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": f\"\"\"I bought a laptop carrying case and it turned out to be \n",
    "             the wrong size. I need to return it.\"\"\",\n",
    "    \"order_id\": 12345,\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}\n",
    "\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a96c8",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Define order_id as a string\n",
    "input_data = {\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": f\"\"\"I bought a laptop carrying case and it turned out to be \n",
    "             the wrong size. I need to return it.\"\"\",\n",
    "    \"order_id\": \"12345\",\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}\n",
    "\n",
    "# Validate the user input data\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ba735",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Define name field as an integer\n",
    "input_data = {\n",
    "    \"name\": 99999,\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": f\"\"\"I bought a laptop carrying case and it turned out to be \n",
    "             the wrong size. I need to return it.\"\"\",\n",
    "    \"order_id\": 12345,\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}\n",
    "\n",
    "# Validate the user input data\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b6dfd",
   "metadata": {},
   "source": [
    "### Try starting with JSON data as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fced4d7",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# Define user input as JSON data\n",
    "json_data = '''\n",
    "{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I bought a keyboard and mouse and was overcharged.\",\n",
    "    \"order_id\": 12345,\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse the JSON string into a Python dictionary\n",
    "input_data = json.loads(json_data)\n",
    "print(\"Parsed JSON:\", input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa83a9c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Validate the user iput data\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0bf4f",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "# Try different JSON input\n",
    "json_data = '''\n",
    "{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"My account has been locked for some reason.\",\n",
    "    \"order_id\": \"01234\",\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# Parse the JSON into a Python dictionary\n",
    "input_data = json.loads(json_data)\n",
    "print(\"Parsed JSON:\", input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da043b60",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Validate the customer support data from JSON with non-standard formats\n",
    "user_input = validate_user_input(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c4b1b",
   "metadata": {},
   "source": [
    "### Try the `model_validate_json` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7564a7d",
   "metadata": {},
   "source": [
    "### Note: the following cell will produce a validation error. You can correct the error by following along with the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad952a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Parse JSON and validate user input data in one step using model_validate_json method\n",
    "user_input = UserInput.model_validate_json(json_data)\n",
    "print(user_input.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31772700",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you learned how to use Pydantic models to validate user input for a customer support scenario. By defining clear data models and handling validation errors, you can ensure your code only works with well-formed data. This approach helps you build more robust and reliable applications, and sets the stage for more advanced validation and structured output in future lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18aec7",
   "metadata": {},
   "source": [
    "# Lesson 3: Prompting for structure and setting up a retry method \n",
    "\n",
    "In this notebook, you'll learn how to combine Pydantic with retry strategies to reliably extract structured output from an LLM.\n",
    "\n",
    "By the end, you'll be able to:\n",
    "- Define structured data models for LLM responses\n",
    "- Build robust retry mechanisms for validation errors\n",
    "- Create reusable functions for LLM interactions\n",
    "\n",
    "---\n",
    "\n",
    "### Import packages and initialize the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663f423",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from pydantic import BaseModel, ValidationError, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "import json\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831dfbb9",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Load environment variables for API access\n",
    "load_dotenv()\n",
    "# Initialize OpenAI client for API calls\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014bd26",
   "metadata": {},
   "source": [
    "### Define some sample input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8446f",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Define a JSON string representing user input\n",
    "user_input_json = '''\n",
    "{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I forgot my password.\",\n",
    "    \"order_number\": null,\n",
    "    \"purchase_date\": null\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf1220",
   "metadata": {},
   "source": [
    "### Define your UserInput data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3d7bf",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Define UserInput model\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df5466",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Create UserInput instance from JSON data\n",
    "user_input = UserInput.model_validate_json(user_input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8337578",
   "metadata": {},
   "source": [
    "### Create a new data model called CustomerQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7354431",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Define the CustomerQuery model that inherits from UserInput\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a42dae9",
   "metadata": {},
   "source": [
    "### Construct a prompt with example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fbbb8",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Create a prompt with generic example data to guide LLM.\n",
    "example_response_structure = f\"\"\"{{\n",
    "    name=\"Example User\",\n",
    "    email=\"user@example.com\",\n",
    "    query=\"I ordered a new computer monitor and it arrived with the screen cracked. I need to exchange it for a new one.\",\n",
    "    order_id=12345,\n",
    "    purchase_date=\"2025-12-31\",\n",
    "    priority=\"medium\",\n",
    "    category=\"refund_request\",\n",
    "    is_complaint=True,\n",
    "    tags=[\"monitor\", \"support\", \"exchange\"] \n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12cb08",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# Create prompt with user data and expected JSON structure\n",
    "prompt = f\"\"\"\n",
    "Please analyze this user query\\n {user_input.model_dump_json(indent=2)}:\n",
    "\n",
    "Return your analysis as a JSON object matching this exact structure \n",
    "and data types:\n",
    "{example_response_structure}\n",
    "\n",
    "Respond ONLY with valid JSON. Do not include any explanations or \n",
    "other text or formatting before or after the JSON object.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da900118",
   "metadata": {},
   "source": [
    "### Define a function to call an LLM and try it with your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0693378",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Define a function to call the LLM\n",
    "def call_llm(prompt, model=\"gpt-4o\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31aebc",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Get response from LLM\n",
    "response_content = call_llm(prompt)\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b2ed3",
   "metadata": {},
   "source": [
    "### Validate the LLM output using your CustomerQuery model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9eded",
   "metadata": {},
   "source": [
    "### Note: the following cell will produce a validation error. This is expected. You can simply proceed with the rest of the notebook as cells below do not depend on this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a28c96",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Attempt to parse the response into CustomerQuery model\n",
    "valid_data = CustomerQuery.model_validate_json(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc028767",
   "metadata": {},
   "source": [
    "### Define a function for error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4eac4c",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# Define a function to validate an LLM response\n",
    "def validate_with_model(data_model, llm_response):\n",
    "    try:\n",
    "        validated_data = data_model.model_validate_json(llm_response)\n",
    "        print(\"data validation successful!\")\n",
    "        print(validated_data.model_dump_json(indent=2))\n",
    "        return validated_data, None\n",
    "    except ValidationError as e:\n",
    "        print(f\"error validating data: {e}\")\n",
    "        error_message = (\n",
    "            f\"This response generated a validation error: {e}.\"\n",
    "        )\n",
    "        return None, error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6386ae2",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Test your validation function with the LLM response\n",
    "validated_data, validation_error = validate_with_model(\n",
    "    CustomerQuery, response_content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a45068",
   "metadata": {},
   "source": [
    "### Define a function to create a retry prompt including error details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4c3ba",
   "metadata": {
    "height": 506
   },
   "outputs": [],
   "source": [
    "# Define a function to create a retry prompt with error feedback\n",
    "def create_retry_prompt(\n",
    "    original_prompt, original_response, error_message\n",
    "):\n",
    "    retry_prompt = f\"\"\"\n",
    "This is a request to fix an error in the structure of an llm_response.\n",
    "Here is the original request:\n",
    "<original_prompt>\n",
    "{original_prompt}\n",
    "</original_prompt>\n",
    "\n",
    "Here is the original llm_response:\n",
    "<llm_response>\n",
    "{original_response}\n",
    "</llm_response>\n",
    "\n",
    "This response generated an error: \n",
    "<error_message>\n",
    "{error_message}\n",
    "</error_message>\n",
    "\n",
    "Compare the error message and the llm_response and identify what \n",
    "needs to be fixed or removed\n",
    "in the llm_response to resolve this error. \n",
    "\n",
    "Respond ONLY with valid JSON. Do not include any explanations or \n",
    "other text or formatting before or after the JSON string.\n",
    "\"\"\"\n",
    "    return retry_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9d6a8",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Create a retry prompt for validation errors\n",
    "validation_retry_prompt = create_retry_prompt(\n",
    "    original_prompt=prompt,\n",
    "    original_response=response_content,\n",
    "    error_message=validation_error\n",
    ")\n",
    "\n",
    "print(validation_retry_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4136f8d5",
   "metadata": {},
   "source": [
    "### Call the LLM with your retry prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaed200",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Call the LLM with the validation retry prompt\n",
    "validation_retry_response = call_llm(validation_retry_prompt)\n",
    "print(validation_retry_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6bf94",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Attempt to validate retry response from LLM\n",
    "validated_data, validation_error = validate_with_model(\n",
    "    CustomerQuery, validation_retry_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe7564",
   "metadata": {},
   "source": [
    "### Create a second retry prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ac9f0",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Create a second retry prompt for validation errors\n",
    "second_validation_retry_prompt = create_retry_prompt(\n",
    "    original_prompt=validation_retry_prompt,\n",
    "    original_response=validation_retry_response,\n",
    "    error_message=validation_error\n",
    ")\n",
    "\n",
    "print(second_validation_retry_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f17d4",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Call the LLM with the second validation retry prompt\n",
    "second_validation_retry_response = call_llm(\n",
    "    second_validation_retry_prompt\n",
    ")\n",
    "print(second_validation_retry_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414cdf2",
   "metadata": {},
   "source": [
    "### Define a function to handle multiple retries in a feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ffccd",
   "metadata": {
    "height": 659
   },
   "outputs": [],
   "source": [
    "# Define a function to automatically retry an LLM call multiple times\n",
    "def validate_llm_response(\n",
    "    prompt, data_model, n_retry=5, model=\"gpt-4o\"\n",
    "):\n",
    "    # Initial LLM call\n",
    "    response_content = call_llm(prompt, model=model)\n",
    "    current_prompt = prompt\n",
    "\n",
    "    # Try to validate with the model\n",
    "    # attempt: 0=initial, 1=first retry, ...\n",
    "    for attempt in range(n_retry + 1):\n",
    "\n",
    "        validated_data, validation_error = validate_with_model(\n",
    "            data_model, response_content\n",
    "        )\n",
    "\n",
    "        if validation_error:\n",
    "            if attempt < n_retry:\n",
    "                print(f\"retry {attempt} of {n_retry} failed, trying again...\")\n",
    "            else:\n",
    "                print(f\"Max retries reached. Last error: {validation_error}\")\n",
    "                return None, (\n",
    "                    f\"Max retries reached. Last error: {validation_error}\"\n",
    "                )\n",
    "\n",
    "            validation_retry_prompt = create_retry_prompt(\n",
    "                original_prompt=current_prompt,\n",
    "                original_response=response_content,\n",
    "                error_message=validation_error\n",
    "            )\n",
    "            response_content = call_llm(\n",
    "                validation_retry_prompt, model=model\n",
    "            )\n",
    "            current_prompt = validation_retry_prompt\n",
    "            continue\n",
    "\n",
    "        # If you get here, both parsing and validation succeeded\n",
    "        return validated_data, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab75c35",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Test your complete solution with the original prompt\n",
    "validated_data, error = validate_llm_response(\n",
    "    prompt, CustomerQuery\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bff52",
   "metadata": {},
   "source": [
    "### Have a look at the JSON schema of your CustomerQuery data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274df4e2",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Investigate the model_json_schema for CustomerQuery\n",
    "data_model_schema = json.dumps(\n",
    "    CustomerQuery.model_json_schema(), indent=2\n",
    ")\n",
    "print(data_model_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb71c0",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Print the original prompt from above\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f95d8",
   "metadata": {},
   "source": [
    "### Construct a new prompt using the JSON schema of your data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1aa232",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Create new prompt with user input and model_json_schema\n",
    "prompt = f\"\"\"\n",
    "Please analyze this user query\\n {user_input.model_dump_json(indent=2)}:\n",
    "\n",
    "Return your analysis as a JSON object matching the following schema:\n",
    "{data_model_schema}\n",
    "\n",
    "Respond ONLY with valid JSON. Do not include any explanations or \n",
    "other text or formatting before or after the JSON object.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21919a",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Run your validate_llm_response function with the new prompt\n",
    "final_analysis, error = validate_llm_response(\n",
    "    prompt, CustomerQuery\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30963c1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you explored how to combine Pydantic models with retry logic to reliably extract structured data from LLM outputs. You practiced building reusable validation functions and prompts, and saw how robust error handling can help you get consistent, usable results from language models. These techniques will help you confidently scale up your LLM-powered workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Lesson 3: Lesson 4: Using Pydantic Models for Structured LLM Output\n",
    "\n",
    "> This section comes from the uploaded notebook. Execute the cells in sequence. Where needed, earlier imports/utilities are repeated for clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini‑Index\n",
    "\n",
    "- Lesson 4: Using Pydantic Models for Structured LLM Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bb46e",
   "metadata": {},
   "source": [
    "# Lesson 4: Using Pydantic Models for Structured LLM Output\n",
    "\n",
    "In the previous lesson, you implemented retry mechanisms to handle validation errors, which mimics what some structured output frameworks are doing behind the scenes when they handle validation for you.\n",
    "\n",
    "In this lesson, you'll experiment with passing you Pydantic model directly in your API call using different frameworks and LLM providers.\n",
    "\n",
    "By the end of this lesson, you'll be able to:\n",
    "- Use Pydantic models directly in your API calls to LLMs\n",
    "- Reliably receive a properly structured response using a variety of different frameworks and LLM providers.\n",
    "\n",
    "---\n",
    "\n",
    "### Import all required libraries and set up your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11c5e5",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3eab72",
   "metadata": {},
   "source": [
    "### Define your Pydantic models for user input and LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c21e83",
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "# Define the UserInput model for customer support queries\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None\n",
    "\n",
    "# Define the CustomerQuery model that inherits from UserInput\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4d86b",
   "metadata": {},
   "source": [
    "### Provide sample input and validate it using your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ded7c6",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Define your input data as a JSON string\n",
    "user_input_json = '''{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n",
    "    \"order_number\": 12345,\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1bc95",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Validate the user_input_json by creating a UserInput instance\n",
    "user_input = UserInput.model_validate_json(user_input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b48355",
   "metadata": {},
   "source": [
    "### Build a prompt and call the Anthropic API with the instructor package for structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505cb71",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"Analyze the following customer query {user_input} \"\n",
    "    f\"and provide a structured response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363746c",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "# Use Anthropic with Instructor to get structured output\n",
    "anthropic_client = instructor.from_anthropic(\n",
    "    anthropic.Anthropic()\n",
    ")\n",
    "\n",
    "response = anthropic_client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",  \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    response_model=CustomerQuery  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea2ec7",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Inspect the returned structured data\n",
    "print(type(response))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a39682",
   "metadata": {},
   "source": [
    "### Use OpenAI's structured output API with your Pydantic schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d342f4a",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Initialize OpenAI client and call passing CustomerQuery in your API call\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format=CustomerQuery\n",
    ")\n",
    "response_content = response.choices[0].message.content\n",
    "print(type(response_content))\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c716e",
   "metadata": {},
   "source": [
    "### Additional advanced usage and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0facf3a",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Validate the repsonse you got from the LLM\n",
    "valid_data = CustomerQuery.model_validate_json(\n",
    "    response_content\n",
    ")\n",
    "print(type(valid_data))\n",
    "print(valid_data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6a29f",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Try the responses API from OpenAI\n",
    "response = openai_client.responses.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    text_format=CustomerQuery\n",
    ")\n",
    "\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38913864",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Investigate class inheritance structure of the OpenAI response\n",
    "def print_class_inheritence(llm_response):\n",
    "    for cls in type(llm_response).mro():\n",
    "        print(f\"{cls.__module__}.{cls.__name__}\")\n",
    "\n",
    "print_class_inheritence(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92138d5",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Print the response type and content \n",
    "print(type(response.output_parsed))\n",
    "print(response.output_parsed.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb392c18",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "# Try out the Pydantic AI package for defining an agent and getting a structured response\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"google-gla:gemini-2.0-flash\",\n",
    "    output_type=CustomerQuery,\n",
    ")\n",
    "\n",
    "response = agent.run_sync(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54073bc3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Print out the repsonse type and content\n",
    "print(type(response.output))\n",
    "print(response.output.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4a537",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you learned how to use Pydantic models to extract structured, validated output directly from LLMs using both OpenAI and Anthropic APIs. By defining your expected output schema with Pydantic and passing it directly to the API, you can eliminate manual parsing and validation code and receive reliable, well-formed responses in a single API call. This approach lets you focus on designing clear data models and prompts, making your code more maintainable and robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Lesson 4: Lesson 5: Tool Calling with Pydantic Models and OpenAI\n",
    "\n",
    "> This section comes from the uploaded notebook. Execute the cells in sequence. Where needed, earlier imports/utilities are repeated for clarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini‑Index\n",
    "\n",
    "- Lesson 5: Tool Calling with Pydantic Models and OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4e903a",
   "metadata": {},
   "source": [
    "# Lesson 5: Tool Calling with Pydantic Models and OpenAI\n",
    "\n",
    "In this lesson, you'll learn how to use Pydantic models to define tools for OpenAI's tool calling API. You'll see how to reuse your existing models to create robust, validated tool definitions, and how to handle tool calls in your Python code. This lesson builds on your `UserInput` and `CustomerQuery` models from previous lessons.\n",
    "\n",
    "By the end of this lesson, you'll be able to:\n",
    "- Use Pydantic models to define tool schemas for OpenAI's tool calling API\n",
    "- Register your tool with the API using a validated schema\n",
    "- Handle tool calls and validate arguments with Pydantic\n",
    "- Integrate LLM-driven workflows with your own Python functions and data sources\n",
    "\n",
    "---\n",
    "\n",
    "### Import all required libraries and set up your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77381ddd",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr, field_validator\n",
    "from pydantic_ai import Agent\n",
    "from typing import Literal, List, Optional\n",
    "from datetime import datetime, date\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import instructor\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b430dce",
   "metadata": {},
   "source": [
    "### Define your Pydantic models for user input and LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c9ca5",
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "# Define your UserInput model\n",
    "class UserInput(BaseModel):\n",
    "    name: str = Field(..., description=\"User's name\")\n",
    "    email: EmailStr = Field(..., description=\"User's email address\")\n",
    "    query: str = Field(..., description=\"User's query\")\n",
    "    order_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Order ID if available (format: ABC-12345)\"\n",
    "    )\n",
    "    # Validate order_id format (e.g., ABC-12345)\n",
    "    @field_validator(\"order_id\")\n",
    "    def validate_order_id(cls, order_id):\n",
    "        import re\n",
    "        if order_id is None:\n",
    "            return order_id\n",
    "        pattern = r\"^[A-Z]{3}-\\d{5}$\"\n",
    "        if not re.match(pattern, order_id):\n",
    "            raise ValueError(\n",
    "                \"order_id must be in format ABC-12345 \"\n",
    "                \"(3 uppercase letters, dash, 5 digits)\"\n",
    "            )\n",
    "        return order_id\n",
    "    purchase_date: Optional[date] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc3d84",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# Define your CustomerQuery model\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeeff10",
   "metadata": {},
   "source": [
    "### Validate user input and create a CustomerQuery instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d808ad8",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "# Define a function to validate user input\n",
    "def validate_user_input(user_json: str):\n",
    "    \"\"\"Validate user input from a JSON string and return a UserInput \n",
    "    instance if valid.\"\"\"\n",
    "    try:\n",
    "        user_input = (\n",
    "            UserInput.model_validate_json(user_json)\n",
    "        )\n",
    "        print(\"user input validated...\")\n",
    "        return user_input\n",
    "    except Exception as e:\n",
    "        print(f\" Unexpected error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc275d7c",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "# Define a function to call an LLM using Pydantic AI to create an instance of CustomerQuery\n",
    "def create_customer_query(valid_user_json: str) -> CustomerQuery:\n",
    "    customer_query_agent = Agent(\n",
    "        model=\"google-gla:gemini-2.0-flash\",\n",
    "        output_type=CustomerQuery,\n",
    "    )\n",
    "    response = customer_query_agent.run_sync(valid_user_json)\n",
    "    print(\"CustomerQuery generated...\")\n",
    "    return response.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54f05d",
   "metadata": {},
   "source": [
    "### Try out your validation and query creation with sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61c9ab",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# Define user input JSON data\n",
    "user_input_json = '''\n",
    "{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe@example.com\",\n",
    "    \"query\": \"When can I expect delivery of the headphones I ordered?\",\n",
    "    \"order_id\": \"ABC-12345\",\n",
    "    \"purchase_date\": \"2025-12-01\"\n",
    "}\n",
    "'''\n",
    "# Validate user input and create a CustomerQuery\n",
    "valid_data = validate_user_input(user_input_json).model_dump_json()\n",
    "customer_query = create_customer_query(valid_data)\n",
    "print(type(customer_query))\n",
    "print(customer_query.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8aa75d",
   "metadata": {},
   "source": [
    "### Define tool input models for FAQ lookup and order status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808ce03",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Define FAQ Lookup tool input as a Pydantic model\n",
    "class FAQLookupArgs(BaseModel):\n",
    "    query: str = Field(..., description=\"User's query\") \n",
    "    tags: List[str] = Field(\n",
    "        ..., description=\"Relevant keyword tags from the customer query\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f48958",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Define Check Order Status tool input as a Pydantic model\n",
    "class CheckOrderStatusArgs(BaseModel):\n",
    "    order_id: str = Field(\n",
    "        ..., description=\"Customer's order ID (format: ABC-12345)\"\n",
    "    )\n",
    "    email: EmailStr = Field(..., description=\"Customer's email address\")\n",
    "\n",
    "    @field_validator(\"order_id\")\n",
    "    def validate_order_id(cls, order_id):\n",
    "        import re\n",
    "        pattern = r\"^[A-Z]{3}-\\d{5}$\"\n",
    "        if not re.match(pattern, order_id):\n",
    "            raise ValueError(\n",
    "                \"order_id must be in format ABC-12345 \"\n",
    "                \"(3 uppercase letters, dash, 5 digits)\"\n",
    "            )\n",
    "        return order_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc02b40",
   "metadata": {},
   "source": [
    "### Create example FAQ and order databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727a804",
   "metadata": {
    "height": 676
   },
   "outputs": [],
   "source": [
    "# Create a fake FAQ database as a list of entries with keywords\n",
    "faq_db = [\n",
    "    {\n",
    "        \"question\": \"How can I reset my password?\",\n",
    "        \"answer\": \"To reset your password, click 'Forgot Password' on the sign-in page and follow the instructions sent to your email.\",\n",
    "        \"keywords\": [\"password\", \"reset\", \"account\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How long does shipping take?\",\n",
    "        \"answer\": \"Standard shipping takes 3-5 business days. You can track your order in your account dashboard.\",\n",
    "        \"keywords\": [\"shipping\", \"delivery\", \"order\", \"tracking\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can I return an item?\",\n",
    "        \"answer\": \"You can return any item within 30 days of purchase. Visit our returns page to start the process.\",\n",
    "        \"keywords\": [\"return\", \"refund\", \"exchange\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can I delete my account?\",\n",
    "        \"answer\": \"To delete your account, go to your account settings tab and select 'delete account'.\",\n",
    "        \"keywords\": [\"delete\", \"account\", \"remove\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create a fake order database\n",
    "order_db = {\n",
    "    \"ABC-12345\": {\n",
    "        \"status\": \"shipped\", \"estimated_delivery\": \"2025-12-05\",\n",
    "        \"purchase_date\": \"2025-12-01\", \"email\": \"joe@example.com\"\n",
    "    },\n",
    "    \"XYZ-23456\": {\n",
    "        \"status\": \"processing\", \"estimated_delivery\": \"2025-12-15\",\n",
    "        \"purchase_date\": \"2025-12-10\", \"email\": \"sue@example.com\"\n",
    "    },\n",
    "    \"QWE-34567\": {\n",
    "        \"status\": \"delivered\", \"estimated_delivery\": \"2025-12-20\",\n",
    "        \"purchase_date\": \"2025-12-18\", \"email\": \"bob@example.com\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967410e5",
   "metadata": {},
   "source": [
    "### Implement tool functions for FAQ lookup and order status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ec625",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "# Define your FAQ lookup tool\n",
    "def lookup_faq_answer(args: FAQLookupArgs) -> str:\n",
    "    \"\"\"Look up an FAQ answer by matching tags and words in query \n",
    "    to FAQ entry keywords.\"\"\"\n",
    "    query_words = set(word.lower() for word in args.query.split())\n",
    "    tag_set = set(tag.lower() for tag in args.tags)\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for faq in faq_db:\n",
    "        keywords = set(k.lower() for k in faq[\"keywords\"])\n",
    "        score = len(keywords & tag_set) + len(keywords & query_words)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = faq\n",
    "    if best_match and best_score > 0:\n",
    "        return best_match[\"answer\"]\n",
    "    return \"Sorry, I couldn't find an FAQ answer for your question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad844661",
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "# Define your check order status tool\n",
    "def check_order_status(args: CheckOrderStatusArgs):\n",
    "    \"\"\"Simulate checking the status of a customer's order by \n",
    "    order_id and email.\"\"\"\n",
    "    order = order_db.get(args.order_id)\n",
    "    if not order:\n",
    "        return {\n",
    "            \"order_id\": args.order_id,\n",
    "            \"status\": \"not found\",\n",
    "            \"estimated_delivery\": None,\n",
    "            \"note\": \"order_id not found\"\n",
    "        }\n",
    "    if args.email.lower() != order.get(\"email\", \"\").lower():\n",
    "        return {\n",
    "            \"order_id\": args.order_id,\n",
    "            \"status\": order[\"status\"],\n",
    "            \"estimated_delivery\": order[\"estimated_delivery\"],\n",
    "            \"note\": \"order_id found but email mismatch\"\n",
    "        }\n",
    "    return {\n",
    "        \"order_id\": args.order_id,\n",
    "        \"status\": order[\"status\"],\n",
    "        \"estimated_delivery\": order[\"estimated_delivery\"],\n",
    "        \"note\": \"order_id and email match\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691a12c",
   "metadata": {},
   "source": [
    "### Define tool schemas for OpenAI tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64829f3",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "# Define tools for your API call\n",
    "tool_definitions = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_faq_answer\",\n",
    "            \"description\": \"Look up an FAQ answer by matching tags to FAQ entry keywords.\",\n",
    "            \"parameters\": FAQLookupArgs.model_json_schema()\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"check_order_status\",\n",
    "            \"description\": \"Check the status of a customer's order.\",\n",
    "            \"parameters\": CheckOrderStatusArgs.model_json_schema()\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b9825",
   "metadata": {},
   "source": [
    "### Define your support ticket output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9590e3",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "#Define your final output Pydantic models\n",
    "class OrderDetails(BaseModel):\n",
    "    status: str\n",
    "    estimated_delivery: str\n",
    "    note: str\n",
    "\n",
    "class SupportTicket(CustomerQuery):\n",
    "    recommended_next_action: Literal[\n",
    "        'escalate_to_agent', 'send_faq_response', \n",
    "        'send_order_status', 'no_action_needed'\n",
    "    ] = Field(\n",
    "        ..., description=\"LLM's recommended next action for support\"\n",
    "    )\n",
    "    order_details: Optional[OrderDetails] = Field(\n",
    "        None, description=\"Order details if action is send_order_status\"\n",
    "    )\n",
    "    faq_response: Optional[str] = Field(\n",
    "        None, description=\"FAQ response if action is send_faq_response\"\n",
    "    )\n",
    "    creation_date: datetime = Field(\n",
    "        ..., description=\"Date and time the ticket was created\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60555d",
   "metadata": {},
   "source": [
    "### Decide on the next support action using OpenAI tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5bde1",
   "metadata": {
    "height": 642
   },
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define a function to call OpenAI with tools\n",
    "def decide_next_action_with_tools(customer_query: CustomerQuery):\n",
    "    \n",
    "    support_ticket_schema = json.dumps(\n",
    "        SupportTicket.model_json_schema(), indent=2\n",
    "    )\n",
    "    system_prompt = f\"\"\"\n",
    "        You are a helpful customer support agent. Your job is to \n",
    "        determine what support action should be taken for the customer, \n",
    "        based on the customer query and the expected fields in the \n",
    "        SupportTicket schema below. If more information on a particular \n",
    "        order_id or FAQ response would be helpful in responding to the \n",
    "        user query and can be obtained by calling a tool, call the \n",
    "        appropriate tool to get that information. If an order_id is \n",
    "        present in the query, always look up the order status to get \n",
    "        more information on the order.\n",
    "\n",
    "        Here is the JSON schema for the SupportTicket model you must \n",
    "        use as context for what information is expected:\n",
    "        {support_ticket_schema}\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": str(customer_query.model_dump())}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tool_definitions,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "    message = response.choices[0].message\n",
    "    tool_calls = getattr(message, \"tool_calls\", None)\n",
    "    return message, tool_calls, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea3a33",
   "metadata": {},
   "source": [
    "### Inspect the LLM's outputs and tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdbda29",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Call the decide_next_action_with_tools function\n",
    "message, tool_calls, messages = decide_next_action_with_tools(\n",
    "    customer_query\n",
    ")\n",
    "# Investigate the LLM's outputs before proceeding\n",
    "print(\"LLM message:\\n\", json.dumps(message.model_dump(), indent=2))\n",
    "print(\n",
    "    \"\\nTool calls:\\n\", \n",
    "    json.dumps([call.model_dump() for call in tool_calls], indent=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755107c",
   "metadata": {},
   "source": [
    "### Gather tool outputs and prepare for ticket generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede983e8",
   "metadata": {
    "height": 540
   },
   "outputs": [],
   "source": [
    "# Define a function to get tool outputs\n",
    "def get_tool_outputs(tool_calls):\n",
    "    tool_outputs = []\n",
    "    if tool_calls:\n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call.function.name == \"lookup_faq_answer\":\n",
    "                print(\"Agent requested a call to the Lookup FAQ tool...\")\n",
    "                args = FAQLookupArgs.model_validate_json(\n",
    "                    tool_call.function.arguments\n",
    "                )\n",
    "                result = lookup_faq_answer(args)\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": tool_call.id, \"output\": result\n",
    "                })\n",
    "                print(f\"Lookup FAQ tool returned {result}\")\n",
    "            elif tool_call.function.name == \"check_order_status\":\n",
    "                print(\"Agent requested a call to Check Order Status tool...\")\n",
    "                args = CheckOrderStatusArgs.model_validate_json(\n",
    "                    tool_call.function.arguments\n",
    "                )\n",
    "                result = check_order_status(args)\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": tool_call.id, \"output\": result\n",
    "                })\n",
    "                print(f\"Check Order Status tool returned {result}\")\n",
    "    return tool_outputs\n",
    "\n",
    "tool_outputs = get_tool_outputs(tool_calls)\n",
    "\n",
    "# Print tool outputs for inspection\n",
    "print(\"Tool outputs:\\n\", json.dumps(tool_outputs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e57d8",
   "metadata": {},
   "source": [
    "### Generate a structured support ticket using Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe1204",
   "metadata": {
    "height": 642
   },
   "outputs": [],
   "source": [
    "# Create the Anthropic client with Instructor\n",
    "anthropic_client = instructor.from_anthropic(\n",
    "    anthropic.Anthropic()\n",
    ")\n",
    "\n",
    "# Define a function to call Anthropic to generate a support ticket\n",
    "def generate_structured_support_ticket(\n",
    "    customer_query: CustomerQuery, message, tool_outputs: list\n",
    "):\n",
    "    tool_results_str = \"\\n\".join([\n",
    "        f\"Tool: {out['tool_call_id']} Output: {json.dumps(out['output'])}\"\n",
    "        for out in tool_outputs\n",
    "    ]) if tool_outputs else \"No tool calls were made.\"\n",
    "    # Concatenate prompt parts into a single string for Anthropic\n",
    "    prompt = f\"\"\"\n",
    "        You are a support agent. Use all information below to \n",
    "        generate a support ticket as a validated Pydantic model.\n",
    "        Customer query: {customer_query.model_dump_json(indent=2)}\n",
    "        LLM message: {str(message.content)}\n",
    "        Tool results: {tool_results_str}\n",
    "    \"\"\"\n",
    "    # Create the message with structured output\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-7-sonnet-latest\",  \n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        response_model=SupportTicket\n",
    "    )\n",
    "    \n",
    "    support_ticket = response\n",
    "    support_ticket.creation_date = datetime.now()\n",
    "    return support_ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36fa025",
   "metadata": {},
   "source": [
    "### Print your final support ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178b90e",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Run the final step of generating a support ticket and print output\n",
    "support_ticket = generate_structured_support_ticket(\n",
    "    customer_query, message, tool_outputs\n",
    ")\n",
    "print(support_ticket.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b8c9c8",
   "metadata": {},
   "source": [
    "### Full workflow: validate, query, decide, tool, and generate ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3226e",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Define new user input data\n",
    "user_json = '''\n",
    "{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe@example.com\",\n",
    "    \"query\": \"I'm really not happy with this product I bought\",\n",
    "    \"order_id\": \"QWE-34567\",\n",
    "    \"purchase_date\": null\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc970a73",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "# Run the entire pipeline\n",
    "valid_user_json = validate_user_input(user_json).model_dump_json()\n",
    "customer_query = create_customer_query(valid_user_json)\n",
    "message, tool_calls, messages = decide_next_action_with_tools(\n",
    "    customer_query\n",
    ")\n",
    "tool_outputs = get_tool_outputs(tool_calls)\n",
    "support_ticket = generate_structured_support_ticket(\n",
    "    customer_query, message, tool_outputs\n",
    ")\n",
    "print(support_ticket.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec150c7b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you learned how to use Pydantic models to define tools for OpenAI's tool calling API and build sophisticated customer support workflows. You saw how to reuse your existing models to create robust, validated tool definitions, handle tool calls in your Python code, and automatically gather information to generate comprehensive support tickets. This approach demonstrates the power of Pydantic for creating end-to-end validated workflows with LLMs, from input validation to tool definitions to structured output generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
